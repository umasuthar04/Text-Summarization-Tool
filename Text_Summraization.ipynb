{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc667ac8-1d34-4bbe-935b-35e14fd0f7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17fd141-8261-4df2-a04f-aab7754a05c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download required resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5a07ef5-09fb-42dc-a9ac-ced44ade7ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(text, num_sentences=2):\n",
    "    # Tokenize sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Word frequency calculation\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    word_frequencies = {}\n",
    "    for word in word_tokenize(text.lower()):\n",
    "        if word.isalpha() and word not in stop_words:\n",
    "            if word not in word_frequencies:\n",
    "                word_frequencies[word] = 1\n",
    "            else:\n",
    "                word_frequencies[word] += 1\n",
    "    \n",
    "    # Normalize frequencies\n",
    "    max_freq = max(word_frequencies.values())\n",
    "    for word in word_frequencies:\n",
    "        word_frequencies[word] /= max_freq\n",
    "\n",
    "    # Sentence scoring\n",
    "    sentence_scores = {}\n",
    "    for sent in sentences:\n",
    "        for word in word_tokenize(sent.lower()):\n",
    "            if word in word_frequencies:\n",
    "                if len(sent.split()) < 30:  # Ignore very long sentences\n",
    "                    if sent not in sentence_scores:\n",
    "                        sentence_scores[sent] = word_frequencies[word]\n",
    "                    else:\n",
    "                        sentence_scores[sent] += word_frequencies[word]\n",
    "    \n",
    "    # Get top N sentences\n",
    "    summary_sentences = heapq.nlargest(num_sentences, sentence_scores, key=sentence_scores.get)\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a47ec03-2271-4bc8-b380-94e543dca9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“„ Original Text:\n",
      " \n",
      "    Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language. \n",
      "    The ultimate objective of NLP is to read, decipher, understand, and make sense of the human languages in a manner that is valuable. \n",
      "    Most NLP techniques rely on machine learning to derive meaning from human languages. \n",
      "    Some common applications of NLP include chatbots, machine translation, sentiment analysis, and text summarization.\n",
      "    \n",
      "\n",
      "âœ‚ï¸ Summary:\n",
      " \n",
      "    Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language. The ultimate objective of NLP is to read, decipher, understand, and make sense of the human languages in a manner that is valuable.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_text = \"\"\"\n",
    "    Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language. \n",
    "    The ultimate objective of NLP is to read, decipher, understand, and make sense of the human languages in a manner that is valuable. \n",
    "    Most NLP techniques rely on machine learning to derive meaning from human languages. \n",
    "    Some common applications of NLP include chatbots, machine translation, sentiment analysis, and text summarization.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\nðŸ“„ Original Text:\\n\", input_text)\n",
    "    print(\"\\nâœ‚ï¸ Summary:\\n\", summarize_text(input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144fd219-d0a1-4de3-bf4f-5440f4a5292f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
